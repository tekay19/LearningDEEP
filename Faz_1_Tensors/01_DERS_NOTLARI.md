# ğŸ¬ DERS 01: TENSOR MEKANÄ°ÄÄ° - BELLEK DÃœZENÄ° VE STRIDE ANALÄ°ZÄ°

---

## ğŸ“º BLOK 1: PRODÃœKSÄ°YON VE SENARYO (YouTuber Modu)

### ğŸ¯ Video BaÅŸlÄ±ÄŸÄ±
**"PyTorch Tensor'larÄ± Neden NumPy'dan HÄ±zlÄ±? | Stride ve Storage MekanizmasÄ± Deep Dive"**

### ğŸ£ The Hook (0:00-0:45)
> "Ã‡oÄŸu kiÅŸi PyTorch tensor'larÄ±nÄ± sadece 'GPU destekli NumPy' sanÄ±yor. Ama gerÃ§ek ÅŸu: Bir tensor'u transpose ettiÄŸinizde bellekte TEK BÄ°R BYTE bile hareket etmiyor! Peki PyTorch bunu nasÄ±l yapÄ±yor? BugÃ¼n tensor'larÄ±n bellek anatomisine gireceÄŸiz ve `.view()` ile `.reshape()` arasÄ±ndaki farkÄ± Ã¶ÄŸrenince production'da karÅŸÄ±laÅŸtÄ±ÄŸÄ±nÄ±z memory leak'lerin %80'ini Ã§Ã¶zeceksiniz. Hadi baÅŸlayalÄ±m!"

### ğŸ¨ GÃ¶rselleÅŸtirme Ä°puÃ§larÄ±
1. **0:45-1:30**: Ekrana bir 2D matris gÃ¶ster. Transpose butonuna basÄ±ldÄ±ÄŸÄ±nda, bellekteki veri bloÄŸu AYNI kalsÄ±n ama Ã¼zerindeki "okuma yÃ¶nÃ¼ oklarÄ±" 90 derece dÃ¶nsÃ¼n. YanÄ±nda "Zero Copy!" yazÄ±sÄ± belirsin.

2. **3:00-4:00**: Stride animasyonu: 3x4'lÃ¼k bir matris gÃ¶ster. `matrix[1,2]` elemanÄ±na eriÅŸirken, bellek bloÄŸunda "base + 1Ã—4 + 2Ã—1 = 6" hesaplamasÄ±nÄ± adÄ±m adÄ±m animasyonla gÃ¶ster.

3. **6:30-7:15**: Storage paylaÅŸÄ±mÄ±: Ä°ki farklÄ± tensor (orijinal ve sliced) gÃ¶ster. AltlarÄ±nda TEK BÄ°R ortak storage bloÄŸu olsun. Her tensor'un farklÄ± offset'ten baÅŸladÄ±ÄŸÄ±nÄ± renkli ok ile gÃ¶ster.

4. **10:00-11:00**: Contiguous vs Non-contiguous karÅŸÄ±laÅŸtÄ±rmasÄ±: Ä°ki bellek bloÄŸu yan yana. Birinde elemanlar sÄ±ralÄ± (yeÅŸil), diÄŸerinde atlayarak okunuyor (kÄ±rmÄ±zÄ± kesik Ã§izgiler).

---

## ğŸ§  BLOK 3: DERÄ°N TEORÄ°K ANALÄ°Z (Akademisyen Modu)

### ğŸ“ Matematiksel Temeller

#### 1. Stride Hesaplama FormÃ¼lÃ¼
Bir N-boyutlu tensor iÃ§in `i,j,k,...` indeksindeki elemana eriÅŸim:

```
memory_address = base_pointer + (i Ã— stride[0]) + (j Ã— stride[1]) + (k Ã— stride[2]) + ...
```

**Ã–rnek:** `tensor.shape = (3, 4)` iÃ§in:
- `stride = (4, 1)` â†’ Row-major order (C-style)
- `tensor[1, 2]` â†’ `base + 1Ã—4 + 2Ã—1 = base + 6`

**Transpose sonrasÄ±:**
- `stride = (1, 4)` â†’ Column-major order
- Bellekte veri deÄŸiÅŸmedi, sadece stride deÄŸiÅŸti!

#### 2. Storage Offset MatematiÄŸi
Bir tensor'u slice ettiÄŸinizde:

```python
original = torch.arange(12)  # storage: [0,1,2,...,11]
sliced = original[3:9]       # storage_offset = 3
```

`sliced[0]` â†’ `original.storage()[3]` (AynÄ± bellek!)

---

### âš™ï¸ Under The Hood (Kaputun AltÄ±)

#### PyTorch C++ KatmanÄ±nda Neler Oluyor?

**1. TensorImpl SÄ±nÄ±fÄ± (C++)**
PyTorch'un Python API'si altÄ±nda `c10::TensorImpl` sÄ±nÄ±fÄ± Ã§alÄ±ÅŸÄ±r:

```cpp
class TensorImpl {
  Storage storage_;           // Ham veri (1D array)
  int64_t storage_offset_;    // BaÅŸlangÄ±Ã§ noktasÄ±
  SmallVector<int64_t> sizes_;    // Shape bilgisi
  SmallVector<int64_t> strides_;  // AdÄ±m bilgisi
  // ...
};
```

**2. View Ä°ÅŸlemi (Zero-Copy)**
`.view()` Ã§aÄŸrÄ±ldÄ±ÄŸÄ±nda:
- Yeni bir `TensorImpl` oluÅŸturulur
- `storage_` pointer'Ä± KOPYALANMAZ (referans paylaÅŸÄ±lÄ±r)
- Sadece `sizes_` ve `strides_` yeniden hesaplanÄ±r
- **Maliyet:** O(1) - Sabit zaman!

**3. Contiguous KontrolÃ¼**
PyTorch, bir tensor'un contiguous olup olmadÄ±ÄŸÄ±nÄ± ÅŸu ÅŸekilde kontrol eder:

```cpp
bool is_contiguous() {
  int64_t expected_stride = 1;
  for (int i = ndim - 1; i >= 0; i--) {
    if (stride[i] != expected_stride) return false;
    expected_stride *= size[i];
  }
  return true;
}
```

**4. CUDA Kernel Optimizasyonu**
Contiguous tensor'lar GPU'da **coalesced memory access** saÄŸlar:
- Warp iÃ§indeki 32 thread bitiÅŸik adresleri okur â†’ Tek memory transaction
- Non-contiguous tensor â†’ Her thread farklÄ± adresten okur â†’ 32 ayrÄ± transaction!
- **Performans farkÄ±:** 10x-100x hÄ±z kaybÄ± olabilir

---

### ğŸ­ SektÃ¶r Notu: Production OrtamÄ±nda KarÅŸÄ±laÅŸÄ±lan Sorunlar

#### Problem 1: Memory Leak (Bellek SÄ±zÄ±ntÄ±sÄ±)
**Senaryo:** BÃ¼yÃ¼k bir model'den sÃ¼rekli `.view()` ile kÃ¼Ã§Ã¼k tensor'lar Ã§Ä±karÄ±yorsunuz.

```python
# YANLIÅ KULLANIM
big_tensor = torch.randn(10000, 10000)  # 400 MB
for i in range(1000):
    small = big_tensor[i:i+10].view(-1)
    process(small)
# big_tensor hala bellekte! Ã‡Ã¼nkÃ¼ small'lar storage'Ä± referans ediyor.
```

**Ã‡Ã¶zÃ¼m:**
```python
small = big_tensor[i:i+10].clone()  # Yeni storage oluÅŸtur
```

#### Problem 2: ONNX Export HatasÄ±
**Senaryo:** Model'inizi ONNX'e export ederken "RuntimeError: view size is not compatible" hatasÄ±.

**Sebep:** Non-contiguous tensor'da `.view()` kullanÄ±mÄ±.

**Ã‡Ã¶zÃ¼m:**
```python
# Model iÃ§inde
x = x.permute(0, 2, 1)  # Non-contiguous hale gelir
x = x.contiguous()      # ONNX iÃ§in zorunlu!
x = x.view(batch, -1)
```

#### Problem 3: Mobile Deployment (TorchScript)
**Senaryo:** `torch.jit.trace()` ile model export edilirken stride bilgisi kaybolur.

**Ã‡Ã¶zÃ¼m:** TÃ¼m tensor'larÄ± `.contiguous()` ile iÅŸaretle:
```python
@torch.jit.script
def forward(x):
    x = x.contiguous()  # Mobile iÃ§in garanti
    return model(x)
```

---

### ğŸ“Š Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±

| Ä°ÅŸlem | Bellek Kopyalama | Zaman KarmaÅŸÄ±klÄ±ÄŸÄ± | GPU UyumluluÄŸu |
|-------|------------------|-------------------|----------------|
| `.view()` | âŒ HayÄ±r (Zero-copy) | O(1) | âš ï¸ Contiguous gerekir |
| `.reshape()` | âš ï¸ Gerekirse | O(1) veya O(n) | âœ… Her zaman |
| `.clone()` | âœ… Evet | O(n) | âœ… Her zaman |
| `.contiguous()` | âš ï¸ Gerekirse | O(1) veya O(n) | âœ… Her zaman |

---

### ğŸ”¬ Derin DalÄ±ÅŸ: Transpose Neden Bu Kadar HÄ±zlÄ±?

**Soru:** 1 milyar elemanlÄ± bir matrisi transpose etmek neden 0.001 saniye sÃ¼rÃ¼yor?

**Cevap:** Ã‡Ã¼nkÃ¼ hiÃ§bir veri hareket etmiyor!

```python
import torch
import time

big = torch.randn(10000, 10000)  # 100 milyon eleman

start = time.time()
transposed = big.t()
print(f"Transpose sÃ¼resi: {time.time() - start:.6f} saniye")
# Ã‡Ä±ktÄ±: ~0.000050 saniye (50 mikrosaniye!)

# DoÄŸrulama
print(f"AynÄ± storage? {big.data_ptr() == transposed.data_ptr()}")  # True
```

**AÃ§Ä±klama:**
- `big.stride() = (10000, 1)` â†’ SatÄ±r Ã¶ncelikli
- `transposed.stride() = (1, 10000)` â†’ SÃ¼tun Ã¶ncelikli
- Bellekte veri: `[0,1,2,3,...,99999999]` (DEÄÄ°ÅMEDÄ°!)
- Sadece metadata gÃ¼ncellendi (stride ve shape)

---

### ğŸ“ Akademik Referanslar

1. **Tensor Storage Model:** 
   - "Automatic differentiation in PyTorch" (Paszke et al., 2017)
   - Section 3.2: Storage and View Mechanism

2. **Memory Layout Optimization:**
   - "Halide: A Language for Fast, Portable Computation on Images" (Ragan-Kelley et al., 2013)
   - Stride-based memory access patterns

3. **CUDA Coalesced Access:**
   - NVIDIA CUDA C Programming Guide, Section 5.3.2
   - "Global Memory Coalescing"

---

## âš”ï¸ BLOK 4: MEYDAN OKUMA (Ã–dev)

### ğŸ¯ GÃ¶rev: NumPy ile Stride MekanizmasÄ±nÄ± Yeniden Yaz

**Zorluk Seviyesi:** ğŸ”¥ğŸ”¥ğŸ”¥ (Orta-Ä°leri)

**AÃ§Ä±klama:**
PyTorch'un `view()` ve `transpose()` iÅŸlemlerini **sadece NumPy kullanarak** ve **hiÃ§bir veri kopyalamadan** implemente edin.

**Gereksinimler:**

```python
import numpy as np

class CustomTensor:
    def __init__(self, data: np.ndarray):
        """
        data: 1D NumPy array (storage)
        """
        # TODO: storage, shape, stride, offset deÄŸiÅŸkenlerini tanÄ±mla
        pass
    
    def view(self, *new_shape):
        """
        PyTorch'un .view() metodunu taklit et.
        Yeni bir CustomTensor dÃ¶ndÃ¼r (storage paylaÅŸÄ±mlÄ±).
        """
        # TODO: Yeni stride hesapla, storage'Ä± paylaÅŸ
        pass
    
    def transpose(self, dim0, dim1):
        """
        Ä°ki boyutu yer deÄŸiÅŸtir (stride manipÃ¼lasyonu).
        """
        # TODO: Stride'Ä± deÄŸiÅŸtir, veri kopyalama!
        pass
    
    def __getitem__(self, index):
        """
        Stride kullanarak doÄŸru elemana eriÅŸ.
        """
        # TODO: Stride formÃ¼lÃ¼nÃ¼ uygula
        pass
    
    def is_contiguous(self) -> bool:
        """
        Tensor'un contiguous olup olmadÄ±ÄŸÄ±nÄ± kontrol et.
        """
        # TODO: Stride sÄ±rasÄ±nÄ± kontrol et
        pass

# Test kodu
storage = np.arange(12, dtype=np.float32)
tensor = CustomTensor(storage)
tensor = tensor.view(3, 4)
print(tensor[1, 2])  # Beklenen: 6.0

transposed = tensor.transpose(0, 1)
print(transposed.is_contiguous())  # Beklenen: False
```

**Bonus GÃ¶rev:**
- `contiguous()` metodunu ekle (gerekirse veriyi yeniden dÃ¼zenle)
- `__repr__()` ile tensor'u gÃ¼zel yazdÄ±r
- PyTorch ile sonuÃ§larÄ± karÅŸÄ±laÅŸtÄ±r ve doÄŸrula

**Teslim:**
- GitHub Gist linki veya `.py` dosyasÄ±
- Test sonuÃ§larÄ±nÄ± iÃ§eren ekran gÃ¶rÃ¼ntÃ¼sÃ¼

---

### âœ… BaÅŸarÄ± Kriterleri
1. âœ… HiÃ§bir `np.reshape()` veya `np.transpose()` kullanmadÄ±nÄ±z mÄ±?
2. âœ… Storage'Ä± kopyalamadan view oluÅŸturabildiniz mi?
3. âœ… Stride formÃ¼lÃ¼ doÄŸru Ã§alÄ±ÅŸÄ±yor mu?
4. âœ… PyTorch sonuÃ§larÄ±yla %100 eÅŸleÅŸiyor mu?

---

## ğŸ“š Ek Kaynaklar

- [PyTorch Internals - Tensor Storage](http://blog.ezyang.com/2019/05/pytorch-internals/)
- [Stride Tricks in NumPy](https://numpy.org/doc/stable/reference/generated/numpy.lib.stride_tricks.as_strided.html)
- [CUDA Memory Coalescing](https://developer.nvidia.com/blog/how-access-global-memory-efficiently-cuda-c-kernels/)

---

**ğŸ¬ Sonraki Ders:** `02_tensor_math_gemm.py` - Matris Ã‡arpÄ±mÄ± ve GEMM Optimizasyonu
