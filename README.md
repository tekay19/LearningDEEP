# ğŸš€ PyTorch ile SÄ±fÄ±rdan Ä°leri Seviye Derin Ã–ÄŸrenme MÃ¼hendisliÄŸi

## ğŸ“Œ Genel BakÄ±ÅŸ

**TÃ¼rkiye'nin en kapsamlÄ± ve teknik derinliÄŸi en yÃ¼ksek PyTorch eÄŸitim serisi!**

Bu 50 bÃ¶lÃ¼mlÃ¼k seri, **Senior Developer**'lar iÃ§in hazÄ±rlanmÄ±ÅŸtÄ±r. "For dÃ¶ngÃ¼sÃ¼" anlatmÄ±yoruz; tensÃ¶rlerin bellekte nasÄ±l yerleÅŸtiÄŸini, tÃ¼revin iÅŸlemcide nasÄ±l aktÄ±ÄŸÄ±nÄ±, GPU'nun veriyi nasÄ±l iÅŸlediÄŸini **"Under the Hood"** (Kaputun altÄ±) detaylarÄ±yla anlatÄ±yoruz.

---

## ğŸ¯ Hedef Kitle

âœ… **Python, SQL ve Algoritma bilen Senior Developer'lar**  
âœ… **Derin Ã¶ÄŸrenmeyi sadece API seviyesinde deÄŸil, sistem seviyesinde Ã¶ÄŸrenmek isteyenler**  
âœ… **Production ortamÄ±nda AI/ML sistemleri deploy edecek mÃ¼hendisler**  
âœ… **Akademik araÅŸtÄ±rma yapacak veya kendi framework'Ã¼nÃ¼ yazacak seviyeye ulaÅŸmak isteyenler**

---

## ğŸ“š MÃ¼fredat (50 BÃ¶lÃ¼m)

### ğŸ”§ Faz 1: Tensors & Computational Graph (The Engine)
**KlasÃ¶r:** `Faz_1_Tensors/`

| # | Dosya | Konu | Durum |
|---|-------|------|-------|
| 01 | `01_tensor_mechanics.py` | Tensor vs NumPy, Storage, Offset, Stride | âœ… |
| 02 | `02_tensor_math_gemm.py` | GEMM, Broadcasting, Vectorization | âœ… |
| 03 | `03_indexing_advanced.py` | Masking, Fancy Indexing, View vs Copy | âœ… |
| 04 | `04_manipulation_view_reshape.py` | view(), reshape(), permute(), transpose() | âœ… |
| 05 | `05_gpu_acceleration.py` | CUDA, CPU-GPU Transfer, Bottleneck | âœ… |
| 06 | `06_autograd_engine.py` | DAG, .backward(), Gradient Flow | âœ… |
| 07 | `07_custom_autograd.py` | torch.autograd.Function, Custom Derivatives | âœ… |

---

### ğŸ§  Faz 2: Neural Network Fundamentals (From Scratch)
**KlasÃ¶r:** `Faz_2_Neural_Networks/`

| # | Dosya | Konu | Durum |
|---|-------|------|-------|
| 08 | `08_linear_regression_math.py` | Saf Python ile Regresyon (nn.Module yasak!) | ğŸ”„ |
| 09 | `09_nn_module_architecture.py` | nn.Module SÄ±nÄ±f YapÄ±sÄ±, __init__ ve forward | ğŸ”„ |
| 10 | `10_activation_function_landscape.py` | ReLU, Sigmoid, Tanh, GELU, Swish | ğŸ”„ |
| 11 | `11_loss_landscape.py` | Entropy, CrossEntropy, MSE, Huber Loss | ğŸ”„ |
| 12 | `12_optimizer_algorithms.py` | SGD, Momentum, RMSProp, Adam, AdamW | ğŸ”„ |

---

### ğŸ“Š Faz 3: Data Engineering (ETL for AI)
**KlasÃ¶r:** `Faz_3_Data_Engineering/`

| # | Dosya | Konu | Durum |
|---|-------|------|-------|
| 13 | `13_custom_dataset_structure.py` | __len__, __getitem__ Optimizasyonu | ğŸ”„ |
| 14 | `14_dataloader_multiprocessing.py` | num_workers, pin_memory, collate_fn | ğŸ”„ |
| 15 | `15_transforms_augmentation.py` | On-the-fly Augmentation Pipeline | ğŸ”„ |

---

### ğŸ” Faz 4: The Training Loop (Boilerplate)
**KlasÃ¶r:** `Faz_4_Training_Loop/`

| # | Dosya | Konu | Durum |
|---|-------|------|-------|
| 16 | `16_training_loop_pro.py` | model.train() vs model.eval() | ğŸ”„ |
| 17 | `17_validation_inference.py` | torch.no_grad() vs torch.inference_mode() | ğŸ”„ |
| 18 | `18_checkpointing_serialization.py` | state_dict, Resume Training | ğŸ”„ |
| 19 | `19_tensorboard_logging.py` | Histograms, Loss Curves, Embeddings | ğŸ”„ |
| 20 | `20_early_stopping_regularization.py` | L1/L2, Dropout, Early Stopping | ğŸ”„ |

---

### ğŸ–¼ï¸ Faz 5: Computer Vision (Pixels to Patterns)
**KlasÃ¶r:** `Faz_5_Computer_Vision/`

| # | Dosya | Konu | Durum |
|---|-------|------|-------|
| 21 | `21_convolution_arithmetic.py` | Kernel, Stride, Padding, Receptive Field | ğŸ”„ |
| 22 | `22_pooling_mechanisms.py` | MaxPool, AvgPool, GlobalAveragePool | ğŸ”„ |
| 23 | `23_batch_norm_layer_norm.py` | Normalization, Internal Covariate Shift | ğŸ”„ |
| 24 | `24_cnn_architectures_modern.py` | ResNet, Skip Connections | ğŸ”„ |
| 25 | `25_transfer_learning_surgery.py` | Pretrained Models, Head Replacement | ğŸ”„ |

---

### ğŸ“ Faz 6: Sequence Models & NLP (Time & Context)
**KlasÃ¶r:** `Faz_6_Sequence_Models/`

| # | Dosya | Konu | Durum |
|---|-------|------|-------|
| 26 | `26_rnn_math.py` | RNN HÃ¼cresi, BPTT | ğŸ”„ |
| 27 | `27_lstm_gru_internals.py` | Forget Gate, Input Gate, Output Gate | ğŸ”„ |
| 28 | `28_embeddings_word2vec.py` | nn.Embedding, Lookup Table | ğŸ”„ |
| 29 | `29_seq2seq_architecture.py` | Encoder-Decoder | ğŸ”„ |
| 30 | `30_attention_mechanism_manual.py` | Attention FormÃ¼lÃ¼ (Manuel Kodlama) | ğŸ”„ |

---

### ğŸ¤– Faz 7: Transformers (State of the Art)
**KlasÃ¶r:** `Faz_7_Transformers/`

| # | Dosya | Konu | Durum |
|---|-------|------|-------|
| 31 | `31_self_attention_class.py` | Multi-Head Attention (SÄ±fÄ±rdan) | ğŸ”„ |
| 32 | `32_positional_encoding.py` | Sinusoidal Positional Encoding | ğŸ”„ |
| 33 | `33_layer_norm_residual.py` | Add & Norm, Post-LN vs Pre-LN | ğŸ”„ |
| 34 | `34_transformer_encoder.py` | Tam Transformer Encoder BloÄŸu | ğŸ”„ |
| 35 | `35_transformer_decoder.py` | Masked Multi-Head Attention | ğŸ”„ |

---

### ğŸ¨ Faz 8: Generative AI (GANs & Autoencoders)
**KlasÃ¶r:** `Faz_8_Generative_AI/`

| # | Dosya | Konu | Durum |
|---|-------|------|-------|
| 36 | `36_autoencoder_latent.py` | Latent Space Manipulation | ğŸ”„ |
| 37 | `37_variational_autoencoder.py` | Reparameterization Trick, KL Divergence | ğŸ”„ |
| 38 | `38_gan_minimax.py` | Generator vs Discriminator | ğŸ”„ |
| 39 | `39_dcgan_implementation.py` | Deep Convolutional GAN | ğŸ”„ |

---

### ğŸš€ Faz 9: Deployment & Optimization (Production Grade)
**KlasÃ¶r:** `Faz_9_Deployment/`

| # | Dosya | Konu | Durum |
|---|-------|------|-------|
| 40 | `40_model_quantization.py` | FP32 â†’ INT8 DÃ¶nÃ¼ÅŸÃ¼mÃ¼ | ğŸ”„ |
| 41 | `41_pruning_sparse.py` | NÃ¶ron Budama | ğŸ”„ |
| 42 | `42_torchscript_tracing.py` | JIT Compiler, Tracing | ğŸ”„ |
| 43 | `43_onnx_export.py` | ONNX Export | ğŸ”„ |
| 44 | `44_flask_api_serving.py` | REST API (Batch Inference) | ğŸ”„ |
| 45 | `45_docker_pytorch.py` | GPU Docker Container | ğŸ”„ |

---

### ğŸ¯ Faz 10: Special Projects
**KlasÃ¶r:** `Faz_10_Projects/`

| # | Dosya | Konu | Durum |
|---|-------|------|-------|
| 46 | `46_project_style_transfer.py` | Neural Style Transfer (VGG) | ğŸ”„ |
| 47 | `47_project_sentiment_bert.py` | BERT Fine-tuning (HuggingFace) | ğŸ”„ |
| 48 | `48_project_image_captioning.py` | CNN + LSTM (Image to Text) | ğŸ”„ |
| 49 | `49_project_char_gpt.py` | Mini-GPT (Karpathy Style) | ğŸ”„ |
| 50 | `50_final_review_roadmap.py` | BÃ¼yÃ¼k Ã–zet ve Ä°leri Seviye Yol HaritasÄ± | ğŸ”„ |

---

## ğŸ“– Her Ders Ä°Ã§eriÄŸi

Her ders **4 ana bloktan** oluÅŸur:

### ğŸ¬ BLOK 1: ProdÃ¼ksiyon ve Senaryo (YouTuber Modu)
- **Video BaÅŸlÄ±ÄŸÄ±:** TÄ±klanabilir ve teknik
- **The Hook (0:00-0:45):** Ä°zleyiciyi Ã§eken giriÅŸ
- **GÃ¶rselleÅŸtirme Ä°puÃ§larÄ±:** EditÃ¶r iÃ§in animasyon Ã¶nerileri

### ğŸ BLOK 2: Python Kodu (MÃ¼hendis Modu)
- **Type Hinting:** TÃ¼m fonksiyonlarda profesyonel tip tanÄ±mlarÄ±
- **Docstring:** Dosya ve fonksiyon aÃ§Ä±klamalarÄ±
- **Inline Comments:** "Neden" ve "NasÄ±l" odaklÄ± yorumlar
- **DEBUG & INSPECT:** `.shape`, `.dtype`, `.stride()`, `.device` yazdÄ±rma
- **INTENTIONAL BUG:** Yeni baÅŸlayanlarÄ±n sÄ±k yaptÄ±ÄŸÄ± hatalar ve Ã§Ã¶zÃ¼mleri

### ğŸ§  BLOK 3: Derin Teorik Analiz (Akademisyen Modu)
- **Matematiksel KanÄ±t:** FormÃ¼ller ve kod eÅŸleÅŸmesi
- **Under The Hood:** C++/CUDA seviyesinde aÃ§Ä±klama
- **SektÃ¶r Notu:** Production ortamÄ±nda karÅŸÄ±laÅŸÄ±lan sorunlar

### âš”ï¸ BLOK 4: Meydan Okuma (Ã–dev)
- **ZorlayÄ±cÄ± GÃ¶rev:** Ä°zleyicinin kodu deÄŸiÅŸtirmesi iÃ§in pratik Ã¶dev
- **BaÅŸarÄ± Kriterleri:** AÃ§Ä±k deÄŸerlendirme metrikleri

---

## ğŸ› ï¸ Kurulum

```bash
# Python 3.8+ gerekli
python --version

# PyTorch kurulumu (CUDA varsa)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Ek kÃ¼tÃ¼phaneler
pip install numpy matplotlib tensorboard

# Repo'yu klonla
git clone <repo_url>
cd PyTorch_Derin_Ogrenme_Serisi

# Ä°lk dersi Ã§alÄ±ÅŸtÄ±r
python Faz_1_Tensors/01_tensor_mechanics.py
```

---

## ğŸ“ NasÄ±l KullanÄ±lÄ±r?

1. **SÄ±rayla Ä°lerle:** Dersler birbirine baÄŸlÄ±, atlama yapma
2. **Kodu Ã‡alÄ±ÅŸtÄ±r:** Her dersi mutlaka Ã§alÄ±ÅŸtÄ±r ve Ã§Ä±ktÄ±larÄ± incele
3. **NotlarÄ± Oku:** Her ders iÃ§in `XX_DERS_NOTLARI.md` dosyasÄ±nÄ± oku
4. **Ã–devi Yap:** Meydan okuma gÃ¶revlerini tamamla
5. **Deney Yap:** Parametreleri deÄŸiÅŸtir, ne olduÄŸunu gÃ¶zlemle

---

## ğŸ“Š Gereksinimler

- **Python:** 3.8+
- **PyTorch:** 2.0+
- **RAM:** Minimum 8GB (16GB Ã¶nerilen)
- **GPU:** NVIDIA GPU (CUDA 11.8+) Ã¶nerilen ama zorunlu deÄŸil
- **Disk:** ~5GB (veri setleri dahil)

---

## ğŸ¤ KatkÄ±da Bulunma

Bu proje aÃ§Ä±k kaynak deÄŸildir, ancak geri bildirimlerinizi bekliyoruz:
- ğŸ› **Bug Report:** Hata bulursanÄ±z bildirin
- ğŸ’¡ **Ã–neri:** Yeni ders konularÄ± Ã¶nerin
- ğŸ“ **DÃ¼zeltme:** YazÄ±m hatalarÄ± iÃ§in PR gÃ¶nderin

---

## ğŸ“œ Lisans

Â© 2026 - TÃ¼m haklarÄ± saklÄ±dÄ±r. EÄŸitim amaÃ§lÄ± kullanÄ±m serbesttir.

---

## ğŸ“ Ä°letiÅŸim

- **YouTube:** [Kanal Linki]
- **Discord:** [Topluluk Linki]
- **Email:** [Email Adresi]

---

## ğŸŒŸ BaÅŸarÄ± Hikayeleri

> "Bu seriyi bitirdikten sonra PyTorch'un kaynak kodunu okuyabiliyorum!" - **Ahmet K., ML Engineer**

> "Production'da karÅŸÄ±laÅŸtÄ±ÄŸÄ±m memory leak sorununu Ders 01 sayesinde Ã§Ã¶zdÃ¼m." - **Elif Y., Senior Developer**

> "GEMM optimizasyonlarÄ±nÄ± Ã¶ÄŸrendikten sonra modelim 3x hÄ±zlandÄ±!" - **Mehmet S., AI Researcher**

---

## ğŸš€ Hadi BaÅŸlayalÄ±m!

```bash
python Faz_1_Tensors/01_tensor_mechanics.py
```

**Unutma:** Bu sadece bir eÄŸitim serisi deÄŸil, PyTorch'un ruhunu anlamak iÃ§in bir yolculuk! ğŸ”¥

---

**Son GÃ¼ncelleme:** 18 Ocak 2026  
**Versiyon:** 1.0.0  
**Durum:** ğŸ”„ Aktif GeliÅŸtirme (7/50 ders tamamlandÄ± - Faz 1 âœ… TamamlandÄ±!)
